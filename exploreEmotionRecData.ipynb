{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "Pandas is a popular python library for working with data through a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow.contrib\n",
      "\u001b[31m  ERROR: Could not find a version that satisfies the requirement tensorflow.contrib (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow.contrib\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow.contrib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-186ec1327284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-186ec1327284>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# get vgg16 outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mx_train_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vgg16_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mx_test_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vgg16_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-186ec1327284>\u001b[0m in \u001b[0;36mget_vgg16_output\u001b[0;34m(vgg16, array_input, n_feature_maps)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mvg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicate_input_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feature_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mpicture_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adamax\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "# from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--csv_file', type=str, required=True)\n",
    "# parser.add_argument('--export_path', type=str, required=True)\n",
    "# # OPTIONAL\n",
    "# parser.add_argument('--batch_size', type=int, default=1)\n",
    "# parser.add_argument('--n_epochs', type=int, default=1)\n",
    "# parser.add_argument('--debug', dest='debug', action='store_true')\n",
    "\n",
    "#FLAGS = parser.parse_args()\n",
    "\n",
    "batch_size_ = 10\n",
    "n_epochs_ = 1\n",
    "csv_file_ = \"/Users/vkhota/Documents/School2019-20/eecs442/HW1/finalproject/fer2013.csv\"\n",
    "export_path_ = \"./export\"\n",
    "\n",
    "\n",
    "# if (FLAGS.debug):\n",
    "#     FLAGS.batch_size = 10\n",
    "    \n",
    "NUM_CLASSES = 7\n",
    "IMG_SIZE = 48\n",
    "\n",
    "# TODO: Use the 'Usage' field to separate based on training/testing\n",
    "TRAIN_END = 28708\n",
    "TEST_START = TRAIN_END + 1\n",
    "\n",
    "\n",
    "def split_for_test(list):\n",
    "    train = list[0:TRAIN_END]\n",
    "    test = list[TEST_START:]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def pandas_vector_to_list(pandas_df):\n",
    "    py_list = [item[0] for item in pandas_df.values.tolist()]\n",
    "    return py_list\n",
    "\n",
    "\n",
    "def process_emotion(emotion):\n",
    "    \"\"\"\n",
    "    Takes in a vector of emotions and outputs a list of emotions as one-hot vectors.\n",
    "    :param emotion: vector of ints (0-7)\n",
    "    :return: list of one-hot vectors (array of 7)\n",
    "    \"\"\"\n",
    "    emotion_as_list = pandas_vector_to_list(emotion)\n",
    "    y_data = []\n",
    "    for index in range(len(emotion_as_list)):\n",
    "        y_data.append(emotion_as_list[index])\n",
    "\n",
    "    # Y data\n",
    "    y_data_categorical = np_utils.to_categorical(y_data, NUM_CLASSES)\n",
    "    return y_data_categorical\n",
    "\n",
    "\n",
    "def process_pixels(pixels, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Takes in a string (pixels) that has space separated ints. Will transform the ints\n",
    "    to a 48x48 matrix of floats(/255).\n",
    "    :param pixels: string with space separated ints\n",
    "    :param img_size: image size\n",
    "    :return: array of 48x48 matrices\n",
    "    \"\"\"\n",
    "    pixels_as_list = pandas_vector_to_list(pixels)\n",
    "\n",
    "    np_image_array = []\n",
    "    for index, item in enumerate(pixels_as_list):\n",
    "        # 48x48\n",
    "        data = np.zeros((img_size, img_size), dtype=np.uint8)\n",
    "        # split space separated ints\n",
    "        pixel_data = item.split()\n",
    "\n",
    "        # 0 -> 47, loop through the rows\n",
    "        for i in range(0, img_size):\n",
    "            # (0 = 0), (1 = 47), (2 = 94), ...\n",
    "            pixel_index = i * img_size\n",
    "            # (0 = [0:47]), (1 = [47: 94]), (2 = [94, 141]), ...\n",
    "            data[i] = pixel_data[pixel_index:pixel_index + img_size]\n",
    "\n",
    "        np_image_array.append(np.array(data))\n",
    "\n",
    "    np_image_array = np.array(np_image_array)\n",
    "    # convert to float and divide by 255\n",
    "    np_image_array = np_image_array.astype('float32') / 255.0\n",
    "    return np_image_array\n",
    "\n",
    "\n",
    "def get_vgg16_output(vgg16, array_input, n_feature_maps):\n",
    "    vg_input = duplicate_input_layer(array_input, n_feature_maps)\n",
    "\n",
    "    picture_train_features = vgg16.predict(vg_input)\n",
    "    del (vg_input)\n",
    "\n",
    "    feature_map = np.empty([n_feature_maps, 512])\n",
    "    for idx_pic, picture in enumerate(picture_train_features):\n",
    "        feature_map[idx_pic] = picture\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "def duplicate_input_layer(array_input, size):\n",
    "    vg_input = np.empty([size, 48, 48, 3])\n",
    "    for index, item in enumerate(vg_input):\n",
    "        item[:, :, 0] = array_input[index]\n",
    "        item[:, :, 1] = array_input[index]\n",
    "        item[:, :, 2] = array_input[index]\n",
    "    return vg_input\n",
    "\n",
    "\n",
    "def main():\n",
    "    # used to get the session/graph data from keras\n",
    "    K.set_learning_phase(0)\n",
    "    # get the data in a Pandas dataframe\n",
    "    raw_data = pd.read_csv(csv_file_)\n",
    "\n",
    "    # convert to one hot vectors\n",
    "    emotion_array = process_emotion(raw_data[['emotion']])\n",
    "    # convert to a 48x48 float matrix\n",
    "    pixel_array = process_pixels(raw_data[['pixels']])\n",
    "\n",
    "    # split for test/train\n",
    "    y_train, y_test = split_for_test(emotion_array)\n",
    "    x_train_matrix, x_test_matrix = split_for_test(pixel_array)\n",
    "\n",
    "    n_train = int(len(x_train_matrix))\n",
    "    n_test = int(len(x_test_matrix))\n",
    "\n",
    "    x_train_input = duplicate_input_layer(x_train_matrix, n_train)\n",
    "    x_test_input = duplicate_input_layer(x_test_matrix, n_test)\n",
    "\n",
    "    # vgg 16. include_top=False so the output is the 512 and use the learned weights\n",
    "    vgg16 = VGG16(include_top=False, input_shape=(48, 48, 3), pooling='avg', weights='imagenet')\n",
    "\n",
    "    # get vgg16 outputs\n",
    "    x_train_feature_map = get_vgg16_output(vgg16, x_train_matrix, n_train)\n",
    "    x_test_feature_map = get_vgg16_output(vgg16, x_test_matrix, n_test)\n",
    "\n",
    "    # build and train model\n",
    "    top_layer_model = Sequential()\n",
    "    top_layer_model.add(Dense(256, input_shape=(512,), activation='relu'))\n",
    "    top_layer_model.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "    top_layer_model.add(Dropout(0.5))\n",
    "    top_layer_model.add(Dense(128, input_shape=(256,)))\n",
    "    top_layer_model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    adamax = Adamax()\n",
    "\n",
    "    top_layer_model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer=adamax, metrics=['accuracy'])\n",
    "\n",
    "    # train\n",
    "    top_layer_model.fit(x_train_feature_map, y_train,\n",
    "                        validation_data=(x_train_feature_map, y_train),\n",
    "                        nb_epoch=n_epochs_, batch_size=batch_size_)\n",
    "    # Evaluate\n",
    "    score = top_layer_model.evaluate(x_test_feature_map,\n",
    "                                     y_test, batch_size=batch_size_)\n",
    "\n",
    "    print(\"After top_layer_model training (test set): {}\".format(score))\n",
    "\n",
    "    # Merge two models and create the final_model_final_final\n",
    "    inputs = Input(shape=(48, 48, 3))\n",
    "    vg_output = vgg16(inputs)\n",
    "    print(\"vg_output: {}\".format(vg_output.shape))\n",
    "    # TODO: the 'pooling' argument of the VGG16 model is important for this to work otherwise you will have to  squash\n",
    "    # output from (?, 1, 1, 512) to (?, 512)\n",
    "    model_predictions = top_layer_model(vg_output)\n",
    "    final_model = Model(input=inputs, output=model_predictions)\n",
    "    final_model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=adamax, metrics=['accuracy'])\n",
    "    final_model_score = final_model.evaluate(x_train_input,\n",
    "                                             y_train, batch_size=batch_size_)\n",
    "    print(\"Sanity check - final_model (train score): {}\".format(final_model_score))\n",
    "\n",
    "    final_model_score = final_model.evaluate(x_test_input,\n",
    "                                             y_test, batch_size=batch_size_)\n",
    "    print(\"Sanity check - final_model (test score): {}\".format(final_model_score))\n",
    "    # config = final_model.get_config()\n",
    "    # weights = final_model.get_weights()\n",
    "\n",
    "    # probably don't need to create a new model\n",
    "    # model_to_save = Model.from_config(config)\n",
    "    # model_to_save.set_weights(weights)\n",
    "    model_to_save = final_model\n",
    "\n",
    "    print(\"Model input name: {}\".format(model_to_save.input))\n",
    "    print(\"Model output name: {}\".format(model_to_save.output))\n",
    "\n",
    "    # Save Model\n",
    "    builder = saved_model_builder.SavedModelBuilder(export_path_)\n",
    "    signature = predict_signature_def(inputs={'images': model_to_save.input},\n",
    "                                      outputs={'scores': model_to_save.output})\n",
    "    with K.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                             tags=[tag_constants.SERVING],\n",
    "                                             signature_def_map={'predict': signature})\n",
    "        builder.save()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file using the pandas method **read_csv** which returns a **DataFrame** object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/fer2013.csv' does not exist: b'data/fer2013.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a74e6bc012a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_data_csv_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/fer2013.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_csv_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/fer2013.csv' does not exist: b'data/fer2013.csv'"
     ]
    }
   ],
   "source": [
    "raw_data_csv_file_name = 'data/fer2013.csv'\n",
    "raw_data = pd.read_csv(raw_data_csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **info()** for a quick description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      "pixels     35887 non-null object\n",
      "Usage      35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35887 entries\n",
    "\n",
    "3 Columns\n",
    "* pixels: **object**\n",
    "* emotion: **int64**\n",
    "* Usage: **object**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## head() for first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* emotion: 0-6\n",
    "* pixels: \"ints separated by spaces\" \n",
    "* Usage: \"Training\" // maybe others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value_counts() for value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image_and_label(x, y):\n",
    "    x_reshaped = x.reshape(48,48)\n",
    "    plt.imshow(x_reshaped, cmap= \"gray\",\n",
    "              interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# x_pixels\n",
    "img = raw_data[\"pixels\"][0]\n",
    "val = img.split(\" \")\n",
    "x_pixels = np.array(val, 'float32')\n",
    "x_pixels /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxI5vTEHs+MYU5H8A3y/ZFbtjQsMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1079638d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "show_image_and_label(x_pixels, raw_data[\"emotion\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
